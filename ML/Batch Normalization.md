![](https://gaussian37.github.io/assets/img/dl/concept/batchnorm/4.png)

## Batch Normalization
- 배치 정규화
- 딥러닝의 기본 중 기본!!
- 정규화(normalization)을 하는 이유는 기본적으로 학습을 더 빨리 하기 위해서
- 각 레이어마다 정규화 하는 레이어를 두어, 변형된 분포가 나오지 않도록 조절하게 하는 것이 배치 정규화
- 배치 정규화는 단순하게 평균과 분산을 구하는 것이 아니라 감마, 베타를 통한 변환을 통해 비선형 성질을 유지하면서 학습될 수 있게 해줌.

## 참고자료 출처
[https://eehoeskrap.tistory.com/430](https://eehoeskrap.tistory.com/430)