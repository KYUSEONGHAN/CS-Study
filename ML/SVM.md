![](https://blog.kakaocdn.net/dn/bE5GSf/btqDohpMUtQ/e7174FjWixOBodHXfXkr50/img.png)

## SVM
- support vector machine
- 분류 과제에 사용할 수 있는 머신러닝 지도학습 모델
- 결정 경계(Decision Boundary), 즉 분류를 위한 기준 선을 정의하는 모델.
- 분류되지 않은 새로운 점이 나타나면 경계의 어느 쪽에 속하는지 확인해서 분류 과제를 수행할 수 있게 된다
- 결국 이 결정 경계를 어떻게 정의하고 계산하는지가 중요하다
- 대부분의 머신러닝 지도 학습 알고리즘은 학습 데이터를 모두 사용하여 모델을 학습한다.
- 그런데 SVM에서는 결정 경계를 정의하는게 결국 서포트 벡터일기 때문에 데이터 포인트 중에서 서포트 벡터만 잘 골라내면 나머지 쓸 데 없는 수많은 포인트들을 무시할 수 있어서 매우 빠르다. 

## 2개의 속성(feature)만 있는 결정 경계 형태
![](https://i.ibb.co/hLH9Qdr/svm01.webp)

## 속성이 3개 있는 결정 경계 형태
![](https://i.ibb.co/PTVmzfg/svm02.webp)
- 결정 경계가 선이 아닌 평면이 된다.
- 고차원이 되면 "초평면" 이라고 부른다

## 최적의 결정 경계
![](https://i.ibb.co/8XRxD05/svm03.webp)
- F가 가장 적절한 결정 경계
- 결정 경계는 데이터 군으로부터 최대한 멀리 떨어지는게 좋다.

## 마진(Margin)
![](https://i.ibb.co/tYFd14p/svm04.webp)
- 결정 경계와 서포트 벡터 사이의 거리를 의미
- 최적의 결정 경계는 마진을 최대화한다.
- N개의 속성을 가진 데이터에는 최소 n+1개의 서포트 벡터가 존재한다.

## 이상치(outlier)를 얼마나 허용할 것인가.
![](https://i.ibb.co/CVH8WMP/svm06.webp)
- 위의 그림은 아웃라이어를 허용하지 않고 기준을 까다롭게 세운 모양이다
- 이걸 하드 마진(hard margin) 이라고 부른다
- 그리고 서포트 벡터와 결정 경계 사이의 거리가 매우 좁다 -> 마진이 작다
- 이렇게 개별적인 학습 데이터를 다 놓치지 않으려고 아웃라이어를 허용하지 않는 기준으로 결정 경계를 정해버리면 오버피팅(overfiting) 문제가 발생할 수 있다.
- 아래 그림은 아웃라이어들이 너그럽게 기준을 잡았다.
- 이걸 소프트 마진(soft margin)이라고 부른다
- 서포트 벡터와 결정 경계 사이의 거리가 멀어져 마진이 커졌다.
- 대신 너무 대충대충 학습하는 꼴이라 언더피팅(underfiting) 문제가 발생할 수 있다.

## 요약
- 여기까지 이해하면 SVM, 서포트 벡터 머신 알고리즘에 대해 어느정도의 감은 잡은 셈이다.
- 위에서 다룬 내용을 가볍게 요약하면 아래와 같다.
- SVM은 분류에 사용되는 지도학습 머신러닝 모델이다.
- SVM은 서포트 벡터(support vectors)를 사용해서 결정 경계(Decision Boundary)를 정의하고, 분류되지 않은 점을 해당 결정 경계와 비교해서 분류한다.
- 서포트 벡터(support vectors)는 결정 경계에 가장 가까운 각 클래스의 점들이다.
- 서포트 벡터와 결정 경계 사이의 거리를 마진(margin)이라고 한다.
- SVM은 허용 가능한 오류 범위 내에서 가능한 최대 마진을 만들려고 한다.
- 파라미터 C는 허용되는 오류 양을 조절한다. C 값이 클수록 오류를 덜 허용하며 이를 하드 마진(hard margin)이라 부른다. 반대로 C 값이 작을수록 오류를 더 많이 허용해서 소프트 마진(soft margin)을 만든다.
- SVM에서는 선형으로 분리할 수 없는 점들을 분류하기 위해 커널(kernel)을 사용한다.
- 커널(kernel)은 원래 가지고 있는 데이터를 더 높은 차원의 데이터로 변환한다. 2차원의 점으로 나타낼 수 있는 데이터를 다항식(polynomial) 커널은 3차원으로, RBF 커널은 점을 무한한 차원으로 변환한다.
- RBF 커널에는 파라미터 감마(gamma)가 있다. 감마가 너무 크면 학습 데이터에 너무 의존해서 오버피팅이 발생할 수 있다.

## 참고자료 출처
[https://hleecaster.com/ml-svm-concept/](https://hleecaster.com/ml-svm-concept/)
[https://angeloyeo.github.io/2020/09/30/SVM.html](https://angeloyeo.github.io/2020/09/30/SVM.html)