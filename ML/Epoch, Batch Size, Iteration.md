![](https://velog.velcdn.com/images/cosmos/post/403bd202-42a4-4daa-b543-87fedf5faebd/image.png)

## Epoch
- 1~1000번의 각 데이터를 모델에서 몇 번씩 복습할 것인지에 대한 횟수를 의미.
- 가령, 5 epoch 라고 하면, 훈련 데이터셋을 순서대로 모델에서 input으로 받는 과정을 5번 연속 수행하며 순전파 및 역전파 과정르 반복하여 거친다는 것으로 이해하면 된다.
- 대체적으로 복습 횟수가 너무 적으면 데이터를 제대로 학습할 수 없고(underfit), 복습 횟수가 일정 횟수 이상이면 추가적인 성능 효과가 거의 사라지게 된다.
        
## Batch Size
- 전체 트레이닝 데이터 셋을 여러 작은 그룹으로 나누었을 때, batch size는 하나의 소그룹에 속하는 데이터 수를 의미.
- 전체 트레이닝 셋을 작게 나누는 이유는 트레이닝 데이터를 통째로 신경망에 넣으면 비효율적인 리소스 사용으로 학습 시간이 오래 걸리기 때문.
        
## Iteration
- iteration은 1-epoch을 마치는데 필요한 미니배치 갯수를 의미.
- 다른 말로, 1-epoch을 마치는데 필요한 파라미터 업데이트 횟수.
- 예를 들어, 700개의 데이터를 100개씩 7개의 미니배치로 나누었을 때, 1-epoch을 위해서는 7-iteration이 필요하며 7번의 파라미터 업데이트가 진행된다.

    
## 참고 자료 출처 

[https://m.blog.naver.com/qbxlvnf11/221449297033](https://m.blog.naver.com/qbxlvnf11/221449297033)